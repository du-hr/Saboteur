\documentclass[12pt,twoside,letterpaper]{article}
%NOTE: This report format is
\usepackage{lipsum}
\bibliographystyle{plain}
\newenvironment{longlisting}{\captionsetup{type=listing}}{}
\setlength{\parskip}{1em}
% include files that load packages and define macros
\input{includes} % various packages needed for maths etc.
\input{notation} % short-hand notation and macros


%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
% front page
\input{titlepage}
%%%%%%%%%%%%%%%%%%%%%%%%%%% table of content
%If a table of content is needed, simply uncomment the following lines
\tableofcontents
\newpage
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%% Main document
\section{Introduction}
The project is based on a on a specific version of a card game called Saboteur, which was originally introduced back in 2004. In this version, there are 5 types of cards available, namely Tile, Malus, Bonus, Destroy, and Map, on a  restricted board of size (15,15). The goal of the project is to implement a computer agent with artificial intelligence called \mintinline{java}{StudentPlayer} defined in \mintinline{java}{public class StudentPlayer extends SaboteurPlayer}. \\ The AI agent is supposed to beat another predefined agent whose move in the game is set to be random.
\par There are many constrains to our project, both from the scope of the project itself and several external factors. In the end, the result we obtained was satisfactory. We had a success rate of 33.33\% from our testing rounds of play and we have satisfied all the requirements from the project specification document.

\section{Technical Approach}
\subsection{Description}
Our strategy is a modified version of the Local Optimization Search to head towards the gold nugget objectives, which is based on the knowledge of Hill Climbing and Simulated Annealing we learned in class. In short, our general strategy is to use the Map cards to find the location of the goal, drop cards that are deemed discardable along the way (to maximize the chances of having a favourable hand), and build a path with the best Tile card in hand, determined by the Local Optimization search, towards the goal.
\par There is also an idea of critical region which was integrated in the approach. The critical region in the game is defined to be the area below row 8. Inside the region, since it is close to the target, a special aggressive approach was chosen as using the Malus card whenever possible to reduce the winning possibility of the enemy. Thus, the setup of the critical region was not only to ensure that there are enough cards to build a path to the gold nugget with the help of the cards from the enemy in the beginning, but also to steer the enemy away from winning on the path we built or blocked the path.
\newpage
\par The details of our approach is listed below in the same order as the logic of our \mintinline{java}{StudentPlayer} class:
\begin{enumerate}
  \item Check if the enemy has played a Malus upon the player. If yes, use the the Bonus card in hand if possible.
  \item If the location of gold nugget is still unknown, use the Map card in in hand if possible.
  \item Drop the dead-end Tile cards in hand if possible to maximize the chances of having a hand of more utility.
  The dead-end Tile cards are defined as in \newline
  \mintinline{java}{public static final ArrayList<String> deadEndTileNames} \newline
  in the class constructor.
  The reason for this discarding move is based on the fact the enemy is completely in random. Hence, we believe it is better to discard those cards in exchange of a potential better hand rather than use those to block the path of the other, since the latter also increases the chance polluting the potential path down to the goal. The over 300 runs of the game we ran proved our prediction.
  \item Use the Destroy cards in hand if possible to destroy all dead-end Tile cards currently on the board below the entrance. This is to maximize the chance of successfully reaching down to row 12.
  \item Check the previous conditions. If there is still no viable option available, do as in Listing \ref{simple}:
  \begin{longlisting}
    \begin{minted}
      [escapeinside=||,
      frame=lines,
      framesep=2mm,
      baselinestretch=1.2,
      linenos,
      bgcolor=LightGray]
      {java}
for (SaboteurMove mov : moves) {
  if (mov.getPosPlayed()[0] >= 5) {
    if (mov.getPosPlayed()[1] <= 7 && (mov.getPosPlayed()[1] >= 3))
      return moves.indexOf(mov);
  }
}
  \end{minted}
  \caption{A simple greedy approach when the gold location is unknown.}
  \label{simple}
  \end{longlisting}
  \item Repeat previous steps until the gold nugget location is revealed.
  \item Once the gold location is known, discard the Map cards in hand.
  \item Check if the cards has reached down to the critical region (below row 8). If not, perform simple greedy approach in Listing \ref{simple}.
  \item If reached the critical region, play the Malus card in hand at once. As stated before, this is a special aggressive approach to reduce the winning possibility of the enemy and to reduce the chance that the planned path is being blocked a dead-end Tile.
  \item Next, perform enhanced greedy algorithm in Listing \ref{enhanced} where playing the cross-shape and vertical-stroke shape Tile cards has higher preference in the move.
  \begin{longlisting}
    \begin{minted}
      [escapeinside=||,
      frame=lines,
      framesep=2mm,
      baselinestretch=1.2,
      linenos,
      bgcolor=LightGray]
      {java}
      // the + and | tiles in the critical area have priority
      boolean hasTileVer = false;
      for (SaboteurCard card : cards){
          if (card.getName().equals("Tile:8") ||
          card.getName().equals("Tile:0")||
          card.getName().equals("Tile:6")||
          card.getName().equals("Tile:6_flip")){
              hasTileVer = true;
              break;
          }
      }
      if (!hasTileVer) {
          for (SaboteurMove mov : moves) {
              if (mov.getPosPlayed()[0] > 8) {
                  if (Math.abs(mov.getPosPlayed()[1] - goldCoord[1]) <= 1)
                      return moves.indexOf(mov);
              }
          }}
      else{
          for (SaboteurMove mov : moves){
              if (mov.getPosPlayed()[0] > 8 && mov.getPosPlayed()[0] < 12
              && Math.abs(mov.getPosPlayed()[1] - goldCoord[1]) <= 1
              && (mov.getCardPlayed().getName().equals("Tile:8")||
              mov.getCardPlayed().getName().equals("Tile:0")||
              mov.getCardPlayed().getName().equals("Tile:6")||
              mov.getCardPlayed().getName().equals("Tile:6_flip") ))
                  return moves.indexOf(mov);
          }}
  \end{minted}
  \caption{Enhanced greedy approach}
  \label{enhanced}
  \end{longlisting}
\end {enumerate}

\subsection{Motivation}
There were several other methods that were discussed before we started writing the code, including turning the game into a Constraint Satisfaction Problem (CSP), similar to the 4 queens problem we studied. However, due to the complexity of the Saboteur game, we believed that the CSP approach will not be feasible for us to achieve on time. There was also an attempted approach by Haoran Du of forming the game into a Minimax tree. In the end, the team decided to switch to the Local Search Optimization approach in the end based on the following reasons:
\begin{enumerate}
  \item There is a total of 56 cards distributed among the players, both starting with 7 cards. Thus, there are only 46 turns, or 23 rounds to discard cards that do not fit one's strategy. Furthermore, only two Malus cards are present in the deck, for twice as many Bonus cards. It increases the chances of countering a Malus, which is unfavourable for an aggressive strategy. However, 6 Map cards are in the deck, thus composing almost a ninth of the deck, favouring a greedy strategy. Three Destroy cards can also compose the deck, which allow the destruction of a tile placed on the board, favourable for path building when one of the 9 dead-end tiles available in the deck are placed. The remaining 28 cards are tunnel tiles permitting route building in various directions.
  \item We believe that in order to beat a random agent, the best move would be perform a Local Optimization each time after the enemy has played instead of planning a path from the beginning. We don't suppose a very complex approach or would have a lot more advantages than a greedy algorithm when facing something random.
  \item The enemy is completely random rather than rational. Hence, it is almost impossible to make predictions to the next move of the enemy based on which card was played in the last round. This would make several approaches very hard, for example calculating heuristics of the move, or deciding the min/max agent in $\alpha - \beta$ pruning, if also considering the complexity of the moves or tiles.
\end{enumerate}
\subsection{Theoretical Basis}
\subsubsection{Hill Climbing}
 Hill climbing is a very powerful method using greedy algorithm to determine the local optimization of a problem. It basically compares the outcome of all its available neighbors and choose the best among them. It has the problem of stuck in a local maximum. In this project, all the cards in hand of the agent is considered neighbors. We used the local greedy search to choose the one that has the best chance to reaching down to the (potential) gold location. The details can be seen in Listing \ref{simple} and \ref{enhanced}.
\subsubsection{Simulated Annealing}
Simulated Annealing is an improved version of Hill Climbing. It allows random non-greedy moves to escape the local maximum. In out problem, the default return move is chosen randomly from the list of all moves available. Also, the malus card is only used once inside the critical region, which is a form let the random player doing the process of Simulated Annealing.
\subsubsection{Divide and Conquer}
A divide-and-conquer algorithm works by recursively breaking down a problem into sub-problems, until these become simple enough to be solved directly. The solutions to the sub-problems are then combined to give a solution to the original problem. In this project, the use of the critical region divides the game into two sub-problems. The first one is that when being outside the critical region, we allow bad moves and simply going down using Listing \ref{simple}. The second one is that when being inside the critical region, we use a more dedicated approach to move as close and as fast to the gold tile as possible. This idea of Divide and Conquer makes the solution easier to approach.

\section{Summary of Result}
The result we obtained was satisfactory. We achieved a success rate of 33.33\% from our over 300 rounds of testing. we have satisfied all the requirements from the project specification document. The RAM we used is lower than 500 MB. The calculating time of our algorithm is smaller than 2 seconds. We did not use File I/O in out program.

\section{Reflect and Future Improvement}
The implementation of this local optimization search approach permits a rapid progression and a fast recon of the coordinates of the goal. Furthermore, the different scenarios, depending on whether the goal is known and whether the critical region has been reached, allow the AI agent to choose among the different aspects of the greedy and aggressive strategy accordingly. Using a modified greedy algorithm as well as multiple conditions for analysis of the board and its development, speed and goal-achievement are favoured simultaneously. Additionally, discarding inconvenient cards quickly greatly increases one's chance of having a good hand early on in the game.
\par However, the program does not fully take into account the Destroy cards, which can be extremely advantageous when the opponent's strategy is to sabotage our path progression. Moreover, grid analysis for road finding is not used, thus giving the disadvantage of not being able to predict a path towards the goal, rather only building a tunnel using the legal moves available in direction of its general location. The rudiment nature of the greedy algorithm, although bringing the advantage of speed and best move selection for the current turn, makes the possibility of a long-term approach unlikely to be opted for. For example, if the all the openings are blocked in the beginning by the enemy, the AI agent does not seek for breakthrough from the side, but to go up away from the goal. Ultimately, the biggest disadvantage of the program is the likeliness of never reaching the goal, regardless of whether its location has been revealed, due to the implementation of tile placement.
\par Accordingly, if time permits, we believe there are improvements could be done to drastically improve the performance. We could improve our greedy algorithm by adding more response based on the opponent's move. For example, if the enemy blocks a planned path leading to the gold nugget, a destroy card could be applied. Another issue could be improved is that, inside the critical region, we can add more calculation on best path leading to the tile based on the feature of the Tile cards. In that way, there would less erroneous placed cards in our path.

\vfill
\section*{Students' contributions}
Both of student partners worked together to understand the problem and write the code in this project.
\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
